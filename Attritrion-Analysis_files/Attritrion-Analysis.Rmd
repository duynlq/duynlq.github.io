## Abstract
The CEO and CFO of Frito Lay have provided me with a dataset for the statistics 
of their employees. They have commissioned me to identify the top factors 
that lead to employee attrition and evidence provided by analysis to back them up. 
They are also interested in trends within the dataset, 
as well as machine learning models to predict attrition and monthly income of their employees.

Things we have found include but are not limited to:

- Numerical and categorical correlations within the dataset
- Top factors that negatively influence attrition
- Top factors that negatively influence monthly income

To close off the analysis, I will provide 2 models that I believe 
rank amongst the best when predicting employee attitrion and mothnly income 
that anyone can use for their organizations.

Click here for presentation!

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(DataExplorer)   # plot_missing() | drop_columns()
library(inspectdf)      # inspect_cat() | show_plots()
library(ggpubr)         # ggarrange()
library(corrplot)      
library(e1071)        
library(caret)

set.seed(760397)

```

```{r, echo=FALSE, results='hide'}
#### Import Data ####
getwd()
df = read.csv("CaseStudy2-data.csv")
df_no_attrition = read.csv("CaseStudy2CompSet-No-Attrition.csv")
df_no_salary = read.csv("CaseStudy2CompSet-No-Salary.csv")
```

# Missing Values
```{r, echo=FALSE}
#str(df)
#table(is.na(df))

plot_missing(df)
```

```{r, echo=FALSE, results='hide'}
#### Inspect Attrition ####
prop.table(table(df$Attrition, useNA = "ifany"))

df_Attrition = data.frame(Attrition = table(df$Attrition, useNA = "ifany"))
df_Attrition
```

```{r, echo=FALSE, results='hide'}
#### Zero Variance ####
# Identify the names of zero variance columns
zero_var_col_names = nearZeroVar(df, names = TRUE)
zero_var_col_names

# Remove all zero variance columns
df = drop_columns(df, zero_var_col_names)

# Remove "identification" columns that are not useful for analysis
df = df %>% select(-ID, -EmployeeNumber)

```

```{r, echo=FALSE, results='hide'}
#### Prepare Corr Plot ####
attritionData <- df
str(attritionData$Attrition)

attritionData$Attrition[attritionData$Attrition == "Yes"] = 0
attritionData$Attrition[attritionData$Attrition == "No"] = 1
attritionData$Attrition_num <- as.numeric(as.character(attritionData$Attrition))

str(select_if(attritionData, is.numeric))
```

# Correlation Plot
```{r, echo=FALSE}
corrplot(cor(select_if(attritionData, is.numeric)), method = "square", tl.col = 'black')
```

```{r, echo=FALSE}
#### Model Formula #####
model_formula = c("Age", "DailyRate", "Education", "EnvironmentSatisfaction",
                  "JobInvolvement", "JobLevel", "JobSatisfaction", "MonthlyIncome",
                  "MonthlyRate", "RelationshipSatisfaction", "StockOptionLevel",
                  "TotalWorkingYears", "TrainingTimesLastYear", "WorkLifeBalance",
                  "YearsAtCompany", "YearsInCurrentRole", "YearsWithCurrManager")

#We are giving our model the significant variables seen from the plot above.
```

```{r, echo=FALSE, results='hide'}
# Convert character variables into factors
df[sapply(df, is.character)] = lapply(df[sapply(df, is.character)], as.factor)

# Numeric variables with a categorical nature are converted into factors
df_numeric_cat_vars = df %>% select(Education, EnvironmentSatisfaction, JobInvolvement,
                                    JobSatisfaction, PerformanceRating, 
                                    RelationshipSatisfaction,
                                    WorkLifeBalance) %>% names()
df[df_numeric_cat_vars] = lapply(df[df_numeric_cat_vars], as.factor)

# Sanity check
str(df)
```

# Visuallizing Categorical Variables
```{r, echo=FALSE}
# Inspect the categorical variables with a cool plot
show_plot(inspect_cat(df))
```

```{r, echo=FALSE, results='hide'}
# Plot function
cat_vs_cat_plot <- function(df, x,y){
  ggplot(data = df, aes_string(x = x, fill = y)) + 
    geom_bar(position = "fill", alpha = 0.9) + 
    coord_flip() +
    theme(legend.position="none",
          axis.title.x=element_blank(),
          axis.text.x=element_blank(),
          axis.ticks.x=element_blank(),
          plot.title = element_text(size = 5))
}

# Identify the names of the categorical variables
categorical_variables = df %>% select(-Attrition) %>% select_if(is.factor) %>% names()
categorical_variables
```

### Personal Categorical Metrics
```{r, echo=FALSE}
personal_cat_plot_list <-lapply(categorical_variables[c(6, 10, 3, 4, 13, 14)],
                             function(x) cat_vs_cat_plot(df, x, "Attrition"))
ggarrange(plotlist = personal_cat_plot_list, common.legend = TRUE, legend="bottom",
          nrow = 3, ncol = 2)
```

### Work Categorical Metrics
```{r, echo=FALSE}
work_cat_plot_list <-lapply(categorical_variables[c(8, 2, 9, 7)],
                             function(x) cat_vs_cat_plot(df, x, "Attrition"))
ggarrange(plotlist = work_cat_plot_list, common.legend = TRUE, legend="bottom",
          nrow = 2, ncol = 2)

```

```{r, echo=FALSE}
work_cat_plot_list <-lapply(categorical_variables[c(1, 5, 11, 12)],
                             function(x) cat_vs_cat_plot(df, x, "Attrition"))
ggarrange(plotlist = work_cat_plot_list, common.legend = TRUE, legend="bottom",
          nrow = 2, ncol = 2)

```

##### Attrition:  

1. Is slighty higher with male employees compared to female employees.
2. Is the highest for single people, and lowest for divorced people.
3. Decreases gradually as employees are more educated.
4. Is lowest amongst employees in the Medical and Life Sciences fields.
5. Has an extremely negative influence to an employee's work life balance.
6. Is highest with employees in Sales, and lowest in director/manager roles.
7. Has an extremely negative influence with an employee's involvement with his/her job,
and decreases gradually as she/he is more satisfied with their job.
8. Is highest with employees who travels frequently.
9. Has a highly negative influence with an employee's work environment
10. Is high in overtime employees as expected.

# Visuallizing Numeric Variables
```{r, echo=FALSE, results='hide'}
numerical_variables_names = df %>% select_if(is.numeric) %>% names()
numerical_variables_names

p1 <- df %>% ggplot(aes(x = Age, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("Age")

p2 <- df %>% ggplot(aes(x = DailyRate, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("DailyRate")

p3 <- df %>% ggplot(aes(x = DistanceFromHome, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("DistanceFromHome")

p4 <- df %>% ggplot(aes(x = HourlyRate, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("HourlyRate")

p5 <- df %>% ggplot(aes(x = JobLevel, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("JobLevel")

p6 <- df %>% ggplot(aes(x = MonthlyIncome, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("MonthlyIncome")

p7 <- df %>% ggplot(aes(x = MonthlyRate, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("MonthlyRate")

p8 <- df %>% ggplot(aes(x = NumCompaniesWorked, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("NumCompaniesWorked")

p9 <- df %>% ggplot(aes(x = PercentSalaryHike, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("PercentSalaryHike")

p10 <- df %>% ggplot(aes(x = StockOptionLevel, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("StockOptionLevel")

p11 <- df %>% ggplot(aes(x = TotalWorkingYears, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("TotalWorkingYears")

p12 <- df %>% ggplot(aes(x = TrainingTimesLastYear, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("TrainingTimesLastYear")

p13 <- df %>% ggplot(aes(x = YearsAtCompany, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("YearsAtCompany")

p14 <- df %>% ggplot(aes(x = YearsInCurrentRole, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("YearsInCurrentRole")

p15 <- df %>% ggplot(aes(x = YearsSinceLastPromotion, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("YearsSinceLastPromotion")

p16 <- df %>% ggplot(aes(x = YearsWithCurrManager, fill = Attrition)) + 
  geom_density(alpha = 0.5) +  
  #theme(axis.text.x = element_text(size =7,angle = 45, hjust = 1),axis.title.x=element_blank()) +
  ggtitle("YearsWithCurrManager")

```

### Personal Numerical Metrics
```{r, echo=FALSE}
ggarrange(p1, p3, p8, p11, nrow = 2, ncol = 2,
          common.legend = TRUE, legend="bottom")

```

### Compensation Numerical Metrics
```{r, echo=FALSE}
ggarrange(p2, p4, p6, p7, p9, p10, nrow = 3, ncol = 2,
          common.legend = TRUE, legend="bottom")

```

### Work Numerical Metrics
```{r, echo=FALSE}
ggarrange(p5, p12, p13, p14, p15, p16, nrow = 3, ncol = 2,
          common.legend = TRUE, legend="bottom")

```

##### Attrition:  

1. Is less likely with employees who has worked in more companies.
2. Is the lowest in employees who are closer to work, and reasonably higher with employees who are farther.
3. Is much likely with employees who have around 10 years of experience.
4. Is extremely influential to a monthly income of around $2500.
5. Is extremely unlikely amongst employees with stock options.
6. Is extremely likely with 1st level employees
7. Gradually decreases as job level increases.
8. Is highest with employees of around 1 or 2 years in the company, as well as in their current role.
9. Has a noticeable gap between yes and no for all training times last year except for 4 times.

```{r, echo=FALSE, results='hide'}
#### Split The Data
# 70% of our data is used for training the model,
# and 30% is for testing the model and validate actual values vs predicted values.

# Convert character variables into categorical variables
df = mutate_if(df, is.character, as.factor)

# Convert 
df = mutate_if(df, is.integer, as.factor)

train_indices = createDataPartition(df$Attrition, p = 0.7, list = FALSE)
train = df[train_indices,]
test = df[-train_indices,]

```

# Predicting Attrition
```{r, echo=FALSE, results='hide'}
dim(train)
```

### k-Nearest Neightbors (k-NN)
```{r, echo=FALSE}
train_control = trainControl(method = "repeatedcv", number = 10, repeats = 3)
KNN_model = train(train[,model_formula],
                  as.factor(train$Attrition),
                  method = "knn",
                  trControl = train_control,
                  #preProcess = c("center","scale"), 
                  tuneLength = 20)
KNN_CM = confusionMatrix(table(predict(KNN_model, train[,model_formula]),
                               as.factor(train$Attrition)))
KNN_CM$overall["Accuracy"]
KNN_CM$byClass["Sensitivity"]
KNN_CM$byClass["Specificity"]
```

### Naive Bayes
```{r, echo=FALSE}
naiveBayes_model = naiveBayes(train[,model_formula],
                              as.factor(train$Attrition),
                              laplace = 1)
naiveBayes_CM = confusionMatrix(table(predict(naiveBayes_model, train[,model_formula]),
                                      as.factor(train$Attrition)))
naiveBayes_CM$overall["Accuracy"]
naiveBayes_CM$byClass["Sensitivity"]
naiveBayes_CM$byClass["Specificity"]

# Wrangling competition set
df_no_attrition = mutate_if(df_no_attrition, is.character, as.factor)
df_no_attrition = mutate_if(df_no_attrition, is.integer, as.factor)

df_no_attrition_predict <- predict(naiveBayes_model, df_no_attrition) 

myout = cbind.data.frame(df_no_attrition$ID, df_no_attrition_predict)
colnames(myout) <- c("ID", "Attrition")
write.csv(myout, file ="Case2PredictionsNguyen Attrition.csv", row.names = FALSE)
```

##### Analysis
Our Naive Bayes model represents the original data with 93.92% accuracy, 
95.30% sensitivity, and 86.73% specificity, 
which is greater than the desired minimum of 60% sensitivity and specificity. 
We believe this model is among the best at classifying employee attrition at Fritolay.

It contains the following variables:

1. Age  
2. DailyRate   
3. Education   
4. EnvironmentSatisfaction  
5. JobInvolvement   
6. JobLevel  
7. JobSatisfaction  
8. MonthlyIncome  
9. MonthlyRate  
10. RelationshipSatisfaction  
11. StockOptionLevel  
12. TotalWorkingYears  
13. TrainingTimesLastYear  
14. WorkLifeBalance  
15. YearsAtCompany  
16. YearsInCurrentRole  
17. YearsWithCurrManager  

# Predicting MonthlyIncome
```{r, echo=FALSE}
train_indices = createDataPartition(attritionData$Attrition, p = 0.7, list = FALSE)

train = attritionData[train_indices,]
test = attritionData[-train_indices,]
```

### Linear Regression
```{r, echo=FALSE}
fit = lm(formula = MonthlyIncome ~ Age + Education + JobLevel + MonthlyRate +
                   NumCompaniesWorked + TotalWorkingYears + YearsAtCompany +
                   YearsInCurrentRole + YearsSinceLastPromotion +
                   YearsWithCurrManager, data = train)
summary(fit)$r.squared

predictions = predict(fit, test)
RMSE(test$MonthlyIncome, predictions)

SalaryPred <- predict(fit, df_no_salary) 
myout=cbind.data.frame(df_no_salary$ID,SalaryPred)
colnames(myout) = c("ID","MonthlyIncome")
write.csv(myout, file ="Case2PredictionsNguyen Salary.csv", row.names = FALSE)
```

##### Analysis
Our linear regression model is 91.15% effective at representing the original data.

We achieved a prediction error of $1432.709 which is below our desired maximum of $3000.

We believe this model is among the best at classifying employee attrition at Fritolay.  

It contains the following variables:

1. Age
2. Education
3. JobLevel
4. MonthlyRate
5. NumCompaniesWorked
6. TotalWorkingYears 
7. YearsAtCompany
8. YearsInCurrentRole
9. YearsSinceLastPromotion
10. YearsWithCurrManager
